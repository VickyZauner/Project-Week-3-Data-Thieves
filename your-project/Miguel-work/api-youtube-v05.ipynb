{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#youtube API key:\n",
    "api_key = 'AIzaSyBBouPW0Ug4r5tWzccLsSJetvMZL4edv-Q'\n",
    "#api_key = 'AIzaSyCRbK4w7VdHA0NIPal55C0qX1zpUL_gqaM'\n",
    "#if your are not so sure about how to get this key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we just use \"googleapiclient.discovery\" we will have an error.\n",
    "# We have to use the following line ir order to be able to use the 'build' function.\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "youtube = build('youtube', 'v3', developerKey = api_key )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime(year=2010, month=1, day=1).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "end_time = datetime(year=2011, month=1, day=1).strftime('%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The most important variables. They will define the topic and the time range of the research.\n",
    "search_topic = ['harry potter']\n",
    "start_year = 2013\n",
    "end_year = 2013\n",
    "\n",
    "\n",
    "# This list will store a small DataFrame for each month.\n",
    "list_df_monthly = []\n",
    "\n",
    "\n",
    "for each_year in range(start_year, end_year+1):\n",
    "    for each_month in range(1,13):\n",
    "        \n",
    "        # A il/else loop is created to have a more precisse control of the time range evaluated.\n",
    "        # December will have an expecific expression to avoid errors. The other months will be the same.\n",
    "        if each_month == 12:\n",
    "            start_time = datetime(year=each_year, month= each_month, day=1).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            end_time = datetime(year= each_year, month= each_month, day=31).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "        else:\n",
    "            start_time = datetime(year=each_year, month= each_month, day=1).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "            end_time = datetime(year= each_year, month= each_month+1, day=1).strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "\n",
    "        res = youtube.search().list(part='snippet', q= search_topic, type='video',\n",
    "                                    publishedAfter=start_time,\n",
    "                                    publishedBefore=end_time,\n",
    "                                    maxResults=50).execute()\n",
    "        \n",
    "        #some empty lists are declared. They will store the data.\n",
    "        video_info = []\n",
    "        id_list = []\n",
    "        stats = []\n",
    "        video_statistics=[]\n",
    "\n",
    "\n",
    "        for item in sorted(res['items'], key=lambda x:x['snippet']['publishedAt']):\n",
    "            #print(item['snippet']['title'], item['snippet']['publishedAt'], item['id']['videoId'])\n",
    "\n",
    "            #from here we take the snippet, which has the video name\n",
    "            video_info.append(item['snippet'])\n",
    "\n",
    "            #with this we take the video ID, which will be use as input \n",
    "            id_list.append(item['id']['videoId'])\n",
    "\n",
    "\n",
    "        #this take all the videos_id and analize them \n",
    "        res_video = youtube.videos().list(id=','.join(id_list),part='statistics').execute()\n",
    "\n",
    "        #now we add all of them in a single code line to the variable 'stats'\n",
    "        stats.append(res_video)\n",
    "\n",
    "        #this will iterate throught all the videos stats and it will pick the statisctics\n",
    "        for elem in stats[0]['items']:\n",
    "            #print(elem['statistics'])\n",
    "            video_statistics.append(elem['statistics'])   \n",
    "\n",
    "\n",
    "        #the 2 data sets are created:\n",
    "        df_videos = pd.DataFrame(stats[0]['items'])\n",
    "        df_statistics = pd.DataFrame(video_statistics)\n",
    "\n",
    "        #lets concatenate. super - mega - definitive data set:\n",
    "        data_frames = [df_videos, df_statistics]\n",
    "        data = pd.concat(data_frames, axis = 1)\n",
    "\n",
    "        #some columns are eliminated\n",
    "        data = data.drop(['kind','etag', 'statistics', 'favoriteCount'], axis=1)\n",
    "\n",
    "        #df_info    \n",
    "        df_info = pd.DataFrame(video_info)\n",
    "        df_info_clean = df_info.drop(['channelId', 'description', 'thumbnails', 'liveBroadcastContent'], axis=1)\n",
    "\n",
    "        #the last concat is done. this gives a very clean df\n",
    "        youtube_data = pd.concat([data, df_info_clean], axis = 1)\n",
    "\n",
    "        #this appends this iteration to the big list\n",
    "        list_df_monthly.append(youtube_data)\n",
    "        \n",
    "        #lets save each month as an independent .csv file.\n",
    "        if each_month < 10:\n",
    "            file_name = 'df_youtube_' + search_topic[0] + '_' + str(each_year) + '_0' + str(each_month)+'.csv'\n",
    "        else:\n",
    "            file_name = 'df_youtube_' + search_topic[0] + '_' + str(each_year) + '-' + str(each_month)+'.csv'\n",
    "        \n",
    "        youtube_data.to_csv(file_name)\n",
    "    \n",
    "youtube_df = pd.concat(list_df_monthly)\n",
    "\n",
    "#show this big data set\n",
    "youtube_df\n",
    "\n",
    "#save this big set\n",
    "big_df_name = 'df_youtube_' + search_topic[0] + '_' + str(start_year) + '-' + str(end_year)+'.csv'\n",
    "youtube_df.to_csv(big_df_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
